[ { "title": "kaldi vs wenet：online流程设计对照", "url": "/posts/kaldi-vs-wenet-online%E6%B5%81%E7%A8%8B%E8%AE%BE%E8%AE%A1%E5%AF%B9%E7%85%A7/", "categories": "ASR", "tags": "writing", "date": "2021-12-19 21:10:00 +0800", "snippet": "　　ASR online实现是工程实现必不可少的一环，可以随着用户实时语音流的输入及时返回识别结果，对于用户体验感非常重要。kaldi/wenet都支持全流程的online实现，主要包括online feature extractor、online model inference、online decoding。由于wenet借鉴了kaldi的不少实现思路和代码，所以本文以kaldi为主介绍online实现的整体思路，并在差异化环节分别介绍kaldi和wenet的实现和简单原理，本文还是遵循kaldi的初衷使用“online”(而非“流式”或者“实时”)作为一种谨慎描述。Take care完成一个Online系统，要妥善处理几方面： processing level：一般有三个level，分别为frame-level，chunk-level，utterence-level。hmm-based asr由于遵循一阶马尔可夫假设，基本可以做到frame-level。self-attention based在ASR（短时上下文依赖特性）应用中可以用chunk-level，当然utterence-level会更好。同时在最上层一般都是utterence-level综合决策，如voice activity detection,end-point detection or rescoring 。 offset：全局的偏移量。如kaldi decoder中num_frame_decoded_，wenet中transformer positon encoding。 cache：由于网络的上下文依赖，feature一般需要cache多帧，如kaldi中mfcc或者wenet中的fbank的queue实现。同时网络中间层的输出由于存在复用性，也会进行cache。decode部分同样依赖历史解码信息，在kaldi中的token保存，transformer中decoder层的自回归解码。 interact：不同模块之间的交互逻辑。如feature extractor和model inference模块之间的交互。model在online模式下是如何使用feature的。对于上述细节在kaldi和wenet中再着重展开一下。feature extraction　　wenet基本采用了kaldi中FeaturePipeline的接口和实现逻辑，但是又略有差别。 目的和差别 kaldi wenet waveform输入，kaldi中实现了resampling操作，wenet做了简化 void AcceptWaveform(BaseFloat sampling_rate, constVectorBase &amp;amp;waveform) = 0; void FeaturePipeline::AcceptWaveform(const std::vector&amp;amp; wav); 下层访问接口，kaldi中提供了随机访问的接口，使用NumFramesReady()信号，而wenet严格按照顺序方式生产和消耗。同时当模型需要的特征得不到满足时，会阻塞在ReadOne() void GetFrame(int32 frame, VectorBase *feat); bool ReadOne(std::vector* feat) cache，kaldi中采用了简单的双端队列实现，而wenet考虑到多线程部署问题，采用了更为智能的BlockingQueue，但会阻塞线程。 std::deque&amp;lt;Vector*&amp;gt; items_; BlockingQueue&amp;lt;std::vector&amp;gt; feature_queue_; offset feature_.Size() num_frames_ kaldi中其他有意思的实现 惰性计算，如ivector   model structure and inference　　由于kaldi和wenet采用了完全不同的网络结构，所以该处的实现区别很大，TDNN实现相对简单，而conformer/transformer的实现复杂一些。kaldi将model inference整合成单独的模块，而wenet采用了torch jit script进行模型前向并整合到torch_asr_decoder中。 目的和差别 kaldi wenet feature输入 非阻塞式，NumFramesReady() 阻塞式 下层访问接口，kaldi中提供了LogLikelihood()惰性触发网络计算，而wenet每个chunk直接触发网络前向计算。 BaseFloat LogLikelihood(int32 frame, int32 index); model_-&amp;gt;torch_model() -&amp;gt;run_method(“ctc_activation”, chunk_out) .toTensor()[0]; cache，kaldi中所有的cache内部进行统一管理(内部相对复杂的dilated 1d-cnn cache结构)，只要满足一个chunk的特征数据即可计算。wenet显式传入cache，同时left context feature也需要cache。 所有cache内部管理。 subsampling_cache: subsampling的输出的cache。elayers_output_cache:所有conformer block的输出的cache。conformer_cnn_cache: conformer block内部 causal conv层的左侧依赖的输入cache。 网络结构和上下文，网络基本没有太多共同之处。在subsampling上略有共同点，kaldi 实现了1d-cnn的叠加，wenet使用2d-cnn，优化帧率和解码计算量。kaldi为了避免右侧依赖过长而使用了不对称的网络结构，使右侧依赖相对较小。wenet只依赖左侧chunk和conformer 内部使用左侧依赖的casual cnn，使得只有在subsampling时引入少许右侧依赖。 subsampling: dilated 1d-cnn叠加降低计算量和跳帧解码降低帧率一种可能配置chunk_size =18right_context = 9left_context = 12 subsampling: 2d-cnn直接降低帧率且降低计算量一种可能配置chunk_size =16*4(wenet直接从decoder角度描述chunk_size，则实际的net chunk_size = subsampling_factor*chunk_size)right_context = 6left_context = num_left_chunks*chunk_size decoder　　kaldi一般采用基于WFST结构的HCLG解码图进行解码，而wenet由于端对端网络结构的特殊性，采用了多种解码策略，比较重要的有两种：1.基于WFST结构的TLG解码图进行解码。2.基于CTC prefix beam search的direct decode和attention parallel rescoring。方法1和kaldi基本一致，而方法2和kaldi无关。同时两个decoder的含义略有不同，kaldi decoder只负责给定网络前向结果后的解码搜索。而wenet将网络前向和解码搜索整合到torch_asr_decoder中简化了流程，但是实际的解码在SearchInterface的派生类中实现，当实现为CtcWfstBeamSearch和kaldi几乎一致。　　同时由于基于WFST的解码方式基本依赖左侧，因此具有天然的online特性。对于lattice-faster-online-decoder，相对去之前lattice-faster-decoder实现了更为高效的get partial result，cache也只是为了记录active_tokens_。 目的和差别 kaldi wenet score获取 BaseFloat LogLikelihood(int32 frame, int32 index) ctc_log_probs = model_-&amp;gt;torch_model()&amp;gt;run_method(“ctc_activation”, chunk_out).toTensor()[0];实际由于复用了kaldi的LatticeFasterDecoder，所以当search函数采用kWfstBeamSearch模式时，采用了fake的decodable对象进行接口转换。 decoder lattice-faster-online-decoder lattice-faster-online-decoder Graph结构 HCLG 采用CtcWfstBeamSearch时会在TLG上进行搜索。 采用CtcPrefixBeamSearch时则没有使用WFST。 search strategy beam search, max_active, min_active CtcPrefixBeamSearch: two pass beam pruneCtcWfstBeamSearch: kaldi beam search, blank_skip_thresh skip blank frame. output one-best, n-best, lattice CtcWfstBeamSearch: one-best,n-best,latticeCtcPrefixBeamSearch: one-best,n-best reference[1] https://github.com/kaldi-asr/kaldi[2] https://github.com/wenet-e2e/wenet[3] Wenet网络设计与实现4-Cache - 知乎 (zhihu.com)" }, { "title": "HMM几个应用场景：NLP、TTS、ASR[TODO]", "url": "/posts/HMM%E5%87%A0%E4%B8%AA%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF-NLP-TTS-ASR-TODO/", "categories": "MachineLearning", "tags": "writing", "date": "2021-12-18 21:10:00 +0800", "snippet": "　　" }, { "title": "DNN-based SPSS全流程算法原理：Merlin[TODO]", "url": "/posts/DNN-based-SPSS%E5%85%A8%E6%B5%81%E7%A8%8B%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86-Merlin-TODO/", "categories": "TTS", "tags": "writing", "date": "2021-12-18 21:10:00 +0800", "snippet": "　　" }, { "title": "语音合成不同时期的技术特点和核心原理", "url": "/posts/%E8%AF%AD%E9%9F%B3%E5%90%88%E6%88%90%E4%B8%8D%E5%90%8C%E6%97%B6%E6%9C%9F%E7%9A%84%E6%8A%80%E6%9C%AF%E7%89%B9%E7%82%B9%E5%92%8C%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86/", "categories": "TTS, review", "tags": "writing", "date": "2021-12-04 21:10:00 +0800", "snippet": "　　TTS(Text-to-Speech)本质上是解决输入文本到输入语音的不定长映射问题。和ASR具有很大的相似性，但是又具有one-to-many技术特点而带来诸多难点。各位前辈的技术博客和各类论文都会对TTS技术原理和特点都有专业、详尽的描述，但是想起刚入门时面对众多技术路线，又不知从何下手的困境，觉得还是有必要沉淀一篇带有核心原理的方向性综合论述博文。本文给出不同时期TTS技术的基本特点，同时对核心技术原理进行阐释。技术分类TTS技术大类上基本划分一致，但是在技术子类上尤其涉及End-to-end speech synthesis上，可能有多种划分方法，如： 根据端对端任务覆盖程度：部分功能模块变成端对端任务和全部功能模块变成了端对端任务 根据模型特点：自回归和非自回归模型本文采用自回归和非自回归模型两类介绍曾经的热门模型tacotron1/2和fastspeech1/2/2s。同时在Concatenative speech synthsis之前也有很多技术路线，但是由于略微久远，这里先不在记录了，先关注优先级更高一些的技术路线吧。 技术大类 技术子类 Concatenative speech synthsis diphone synthesisunit selection synthesis Statistical parametric speech synthesis hmm-based parametric speech synthesisdnn-based parametric speech synthesis End-to-end speech synthesis auto-regression model non-autoregression model Concatenative speech synthsis　　拼接法基本思想就是录制特定说话人的语音库，将每句话的按照特定的建模单元进行分割，组成语音候选单元库，在合成阶段根据输入文本从语音候选单元库中，选择合适的基本单元进行拼接重组获得最终合成的语句。每种建模单元对应的候选单元可以有一个或者多个时。diphone是英文常见的建模单元，其候选单元只有一个，也可能获得较好的合成效果，即diphone synthesis。而当候选单元有多个时，需要根据文本上下文选择不同的候选单元，即unit selection synthesis。优缺点可参考paper[3] 优点： high intelligibility and authentic timbre close to the original voice actor 缺点： less natural and emotional，result in less smoothness in stress, emotion, prosody，large databasediphone synthesis　　diphone synthesis，一般指每个基本合成单元的候选单元只有一个，基于双音子的语音合成模型认为协同发音现象主要出现在音素边界上,即相邻单音素的拼接点上,而在音 素中部稳定段的发音比较稳定,所以双音子选择协同发音较为弱的音素稳定段作为拼接点，即diphone可以大幅度减轻在Phone和phone边界处的协同发音问题，在早期英文语音合成 中广泛应应用。diphone synthesis也有unit selection 版本的算法，即每个diphone有多个候选单元。但是最早期的diphone可以使用非常少的diphone set（like: 44 basic units）合成相对流畅的语音。核心步骤： 录音准备预料 分段和对齐（早期对齐直接采用DTW，用来和benchmark语料库进行对齐） 音频片段音质检查和边界检查 基频提取（非常重要，拼接法中的核心算法之一就是PSOLA及其变种: TD-PSOLA,FD-PSOLA,LP-PSOLA…） 根据lexicon将文本转化为phone sequence。 （如果是unit selection可以包含更多模块，如：text analysis, lexicons and prosodic models） 最终从库中选择对应片段使用PSOLA算法进行拼接和处理unit selection synthesis　　　unit selection synthesis，一般指每个基本合成单元的候选单元有多个（ candidates），有多个意味着prosody可控可选，可以合成更加丰富的语句，但是同时意味着需要额外的信息和算法选择合适的 candidate。额外的信息一般指如何从文本获得目标音频信息，算法指根据该音频信息获得对应的最匹配的候选单元序列。　　首先需要通过文本获取target需要满足的条件，有了target的确切要求(音素、上下文、韵律等等)可以通过算法选择合适的 candidate unit，而合适的 candidate要满足两种条件，一种是 candidate要和target 在多种 feature上匹配，另一种要该 candidate要和上下文的 candidate衔接紧密，即声学特征连续性好。在这两个条件的约束下，通过合适的算法就可以选择合理的候选音频片段。a. feature vector衡量target和 candidate的feature vector一般包括以下几个方面： 连续变量：pitch,duration,power 离散变量：前驱phoneme，后继phoneme，是vowel 还是consonant等等。衡量 candidate和context candidate的feature vector一般包括以下几个方面： 连续变量：pitch,cepstral distance,powerQ1:feature 距离衡量方式?　　连续变量直接可以算距离，而离散变量遵循简单的原则，target和unit是一致则为1否则为0。Q2:feature如何提取?　　对文本进行文本分析，获取linguistic feature，通过regression tree可以获得连续变量。离散变量直接通过question set对linguistic feature离散化。b. constraint两个约束表述如下：\\(\\begin{equation}C^{t}\\left( t_{i},u_{i}\\right) =\\sum ^{p}_{j=1}w_{j}^{t}C_{j}^{t}\\left( ti,u_{i}\\right) \\end{equation}\\)\\[\\begin{equation}C^{c}\\left( u_{i-1},u_{i}\\right) =\\sum ^{q}_{j=1}w_{j}^{c}C_{j}^{c}\\left( u_{i-1},u_{i}\\right)\\label{1}\\end{equation}\\]公式(1)为target cost，由多个subcost组成，每个subcost对应一个feature，不同的实现p的取值不同，如p=40。公式(2)为concatenative cost，由多个subcost组成，每个subcost对应一个feature，常见的就是q=3，共三个特征（pitch,cepstral distance,power）。Q1:weights如何选择?　　weights的选择非常关键，选择合适的weights对最终合成的语音音质很重要。有两种方案一种是 weight space search 在有限的参数空间中进行搜索.，另一种regression training可以穷尽参数搜索。c. algorithmviterbi算法+prune算法，这里不再赘述算法原理。Q1: 大型database可能超过100,000 units，如何进行有效搜索？　　数据库搜索和HMM解码问题非常像，当前candidate只依赖当前target，最优hidden sequences对应的就是最优的candidate sequences，转移概率和发射概率分别使用了concatenate cost和target cost代替，所以最优路径的搜索可以选择viterbi算法，同时使用beam search（如：beam=20units）方法可以更快速的解码。Statistical parametric speech synthesis　　统计参数合成法的整体路线已经和最近几年层出不穷各种技术路线基本一致，理解统计参数合成法对于端对端网络真正工程化落地也非常重要。核心三个模块： text analysis :文本分析用于text转化成语言学特征linguistic feature（随着技术发展，该模块功能的输入输出会有所变化），包含了text normalization , grapheme-to-phoneme conversion, word segmentation，prosody prediction，quesitons set等等。 acoustic model and duration model：用于linguistic feature映射成acoustic feature. vocoder ：用于acoustic feature产生语音。从上述关键的三个模块可以看出，其中关键的两个特征是linguistic feature和acoustic feature： linguistic feature：音素在音节的位置信息，前驱音素后置音素，重音、音调标注等等，多达几十种的基于语言学的上下文描述信息。 acoustic feature：取决于vocoder的建模方式。在SPSS技术时期主要的声码器有两种straight和world。两者都是基于source-filter模型，原理基本一致。需要的输入有三种：MGC(mel-generalized coefficients，用于vocal tract的建模)，F0(pitch，用于voiced语音声带激励源建模)，BAP(band aperiodicities，与F0一起用于声带混合激励源的建模，能够让激励更加真实)。　　这两个特征的映射关系可以从hmm-based model给出也可以从dnn-base model给出。但是注意dnn-based model还省去了hmm-based SPSS中的regression tree-based context tying。下文展开linguistic feature和acoustic feature建模原理，但对text normalization和vocoder 粗略描述，在dnn-based SPSS语境下的详细原理可以参照后续关于Merlin[4]（基于dnn-based SPSS的开源python实现）的博文。当我们将文本输入text normalization后，会获得多个离散的linguistic feature。但是要想获得frame-level aoucstic feature还要给出duration prediction和phoneme-level acoutic feature，两种经典方法的解决方案如下。hmm-based SPSS　　更确切地hmm-based SPSS应该称之为regression tree-based SPSS，这是因为决定linguistic feature和acoustic feature映射关系的模型不是hmm而是tree。dnn-based SPSSreference[1] Concatenative Speech Synthesis: A Review[2] PITCH-SYNCHRONOUS WAVEFORM PROCESSING TECHNIQUES FOR TEXT-TO-SPEECH SYNTHESIS USING DIPHONES[3] A Survey on Neural Speech Synthesis[4] Merlin: An Open Source Neural Network Speech Synthesis System" }, { "title": "pitch提取技术路线及在ASR、TTS、变声算法中的应用[TODO]", "url": "/posts/pitch%E6%8F%90%E5%8F%96%E6%8A%80%E6%9C%AF%E8%B7%AF%E7%BA%BF%E5%8F%8A%E5%9C%A8ASR-TTS-%E5%8F%98%E5%A3%B0%E7%AE%97%E6%B3%95%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8-TODO/", "categories": "Feature", "tags": "writing", "date": "2021-12-04 21:10:00 +0800", "snippet": "　　Parallel text-to-speech with pitch prediction pitch在tts中的应用" }, { "title": "写在前面", "url": "/posts/%E5%86%99%E5%9C%A8%E5%89%8D%E9%9D%A2/", "categories": "Thoughts", "tags": "writing", "date": "2021-12-04 14:10:00 +0800", "snippet": "　　本博客用于总结学习、工作中的一些技术，由于时间有限，公式和图片基本没有，之后可能会补上或有了新的感悟重新写一篇，虽然参照了不少论文和前辈博客，但是主要还是靠自己脱稿白话描述，所以用词严谨性不足，可能存在错误，同时虽然不少博文是总结性质的，但是视野受限，片面描述在所难免，但随着技术能力和写作能力提升，博文的阅读体验感也会更佳，曲折中前进。" }, { "title": "内存管理三层次之用户态上层案例分析：HTK内存管理", "url": "/posts/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E4%B8%89%E5%B1%82%E6%AC%A1%E4%B9%8B%E7%94%A8%E6%88%B7%E6%80%81%E4%B8%8A%E5%B1%82%E6%A1%88%E4%BE%8B%E5%88%86%E6%9E%90-HTK%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/", "categories": "LINUX, Memory", "tags": "writing", "date": "2021-11-29 21:10:00 +0800", "snippet": "　　内存管理一直是一个程序设计绕不开的一个话题，尤其是当存在性能瓶颈或内存泄漏时，一个合理的内存分配和释放策略尤为重要。由于之前使用HTK作为快速验证语音相关算法的软件原型时，出现过内存泄漏的问题，借此机会研究了一下HTK的内存设计方法。本文以HTK内存管理设计为例介绍内存管理三个层次的最上层设计应用案例。1 内存管理的一些基本问题1.1 内存管理三个层次　　内存管理实现一般有三个层次，分别为内核态、用户态的底层软件应用和上层软件应用。 内核态　　内核态是操作系统负责内存管理。操作系统直接面对各种物理存储器，利用各种策略进行合理的分配，同时抽象后提供给用户态进行系统调用。 用户态底层　　用户态底层一般是各种高度优化的并面对用户的内存管理器，通过系统调用获得大块内存，然后面对用户的不同内存请求使用不用的策略，如glibc中的ptmalloc2，通过brk和mmap这两个系统调用获取内存空间，又或者google的tcmalloc，tcmalloc在单线程或者高并发时相对ptmalloc2都有很不错的提升。 用户态上层　　用户态上层是用户面向应用直接实现的各种功能库，由于各类应用有不一样的内存分配侧重点，所以在该层面实现一个内存管理器，可以减少和下一层次内存管理器的交互代价，且了解用户的使用逻辑，达到更加轻便和高效的效果。1.2 一个好的内存管理器应该具备哪些优点 分配迅速：对于某些高并发请求类场景，内存分配速度可能会成为一个瓶颈。 释放方便：对于大型应用，可能存在复杂的内存分配逻辑，如果不加以统一管理，很有可能存在内存泄漏的问题。 减少内存碎片：合理的分配和回收内存空间。1.3 用户态内存分配思想 大内存和小内存分开管理，大内存一般利用系统调用，而小内存则更加考验内存管理器的实现能力。 不同层次的精细化管理，如多线程分配问题，不同大小的精细申请内存。 何时选择从内核态申请内存和返还内存。 尽量减少同低层次内存管理器交互也是一个关键因素，越上层的实现可能越高效，当然也可能增加了软件实现成本和迁移成本。2 HTK内存管理　　HTK内存管理是由HMEM模块实现，所有程序通过调用HMEM实现内存分配和释放。　　HTK中很多tools需要为不同的数据结构动态的申请大量的内存。为了能够精准和高效的分配内存，并且能够统一管理内存，HTK实现了自己的内存管理器HMEM。注意HTK的数学计算库等基础模块的内存分配也是利用HMEM，可以说HMEM是HTK很底层的存在。2.1 颗粒度设计大颗粒度划分为三个形态： MHEAP：每次调用该HEAP只能分配固定大小的内存，即无视用户临时意图，但是new/free是可以随机访问的。同时提供global reset，即统一管理。好处就是由于分配的大小固定，所以分配迅速，且支持随机访问，则可以随时进行分配和释放。使用场景有限，一般用于大量重复的结构体等数据结构的内存管理。 随即访问含义：能够从block list中任意block和该block内部的任意位置（任意一个element）分配和回收用户内存。 思想：分配删除都比较方便，但是只对特定大小的结构体好用。 应用场合：大量重复且分配和释放逻辑不确定的结构体，如TOKEN。 MSTACK：每次申请可以获得任意大小的内存，但是new/free只支持LIFO，即入栈出栈模式。同时提供global reset，即统一管理。好处是用户可以申请任意大小的内存，所以应用比较广泛。释放时只能释放位于栈顶的内存块。 LIFO含义：只能从block list中第一个block和该block内部最上层空间分配和回收用户内存。 思想：分配删除受限，但是可以分配任意大小的内存，注意删除时，会把比要删除内存更早分配的所有内存释放，此举意味着最好内存使用逻辑符合后分配先释放原则，用于符合层次调用的内存顺序分配尤其好用，能够保证内存按逻辑释放（防止内存泄漏），如后调用的深层次内存在程序结束时首先被释放。 应用场合：用户申请大小不一致，但是逻辑符合内存后分配先释放原则的层次调用比较好用。 CHEAP：顾名思义直接调用C库，进行任意大小的内存分配，同时可以随机malloc/free，但是无法global reset。 对应代码如下： typedef enum{MHEAP,MSTAK,CHEAP} HEAPTYPE;typedef struct{ char* name; HEAPTYPE type; float growf; size_t elemSize; size_t minElem; size_t maxElem; size_t curElem; size_t totUsed; size_t totAlloc; BlockP heap; Boolean protectStk; }MemHeap; 中颗粒度： block：除了CHEAP，直接遵循glibc实现标准，其他两个以block为颗粒度从下层申请内存。block的大小可以自适应的小幅度增长，受到growf参数支配。 对应代码如下： typedef struct _Block{ size_t numFree; size_t firstFree; size_t numElem; ByteP used; Ptr data; BlockP next; }Block; 小颗粒度： element：一个block内有多个element，MHEAP每个block的elementSize可以是任意大小，而MSTACK每个block的elementSize大小永远是1byte2.2 统一管理使用全局的heapList记录所有类型的内存分配操作：typedef struct _MemHeapRec{ MemHeap *heap; struct _MemHeapRec *next;}MemHeapRec;static MemHeapRec *heapList = NULL; MemHeapRec主要通过RecordHeap和UnRecordHeap两个函数来完成内存堆的记录和擦除操作。维护一个全局的列表，有利于进行统一的操作如：global reset。同时提供了一个很实用的函数PrintHeapStats()，用于查看当前所有已经分配的Heap的状态。2.3 接口设计 上层接口 功能 void CreateHeap(MemHeap *x, char *name, HeapType type, size_t elemSize, float growf, size_t numElem, size_t maxElem) 创建任意一个类型的Heap，并将其记录在heapList中。对于三种Heap创建虽然输入参数一致，但是内部逻辑基本不一致，有些参数可能会失效。 void ResetHeap(MemHeap *x) 重置Heap，对于CHEAP该操作不起作用，MHEAP释放所有的block，而MSTACK会保留第一个block，因此要注意可能会导致内存泄漏。 void DeleteHeap(MemHeap *x) 彻底删除一个HEAP，该操作将某个类型的HEAP直接抹除，释放其所有block，对于MSTACK会额外进行一次block释放，从全局heapList删除其信息，最终删除该HEAP结构体内存。 void *New(MemHeap *x, size_t size) 用户主要接口：从指定类型的堆中分配指定大小的内存 void Dispose(MemHeap *x, void *p) 从指定类型的堆中删除指定的内存指针 核心重要函数 功能 static void *GetElem(BlockP p, size_t elemSize, HeapType type) 从指定的块中分配内存，被New函数调用，用于现有block满足内存申请大小时。 BlockP AllocBlock(size_t size , size_t num , HeapType type) 从下一层如glibc层内存管理器申请内存，被New调用，用于现有block无法满足内存申请大小时。 2.4 代码简析章节2.3所有接口中最能体现内存管理设计思想的函数为以下三个：New(): 从new函数可以看出用户内存被分配时永远使用的是位于block链表的第一个block。 MHEAP是因为及时调整用于用户申请内存分配的block的位置，MSTACK是因为其只能从栈顶分配内存也即第一个block。 MHEAP由于分配的是固定大小的elem，所以有一个table状态表维护分配和释放信息，分配时flag = 1。 MSTACK由于可以是随机大小，同时在block list维度和block内部都遵循栈顶申请和释放准则。 Dispose(): MHEAP可以删除block list维度和block内部任意位置的内存，MSTACK只能删除block list维度和block内部维度上的栈顶内存，因此会把之前所有比指针p先分配但是不属于指针p指向的内存的所有内存全部释放掉，包括其他block。GetElem(): MHEAP从任意block分配一个合适的固定elementSize大小的内存。 MSTACK栈顶block及block内部顶部分配合适的任意大小的内存。void *New(MemHeap *x, size_t size) //返回从内存堆x分配大小为size的新元素指针{ void *q; BlockP newp; size_t num,bytes,*ip,chdr; Boolean noSpace; Ptr *pp; /*检查当前堆是否创建，只有没有创建的堆才会elemSize = 0*/ if (x-&amp;gt;elemSize &amp;lt;= 0) HError(5174, &quot;New: heap %s not initialised&quot;, (x-&amp;gt;name==NULL) ? &quot;Unnamed&quot; : x-&amp;gt;name); switch(x-&amp;gt;type) { case MHEAP: // ATTENTION:用户每次只能申请elemSize大小的内存，但是每次申请的新block大小是num* elemSize大小的内存 // 不论新申请的block还是已存在的满足要求的block都会被放到表头。这样每次都是从表头分配内存。 if (size != 0 &amp;amp;&amp;amp; size != x-&amp;gt;elemSize) HError(5173,&quot;New: MHEAP req for %u size elem from heap %s size %u&quot;, size , x-&amp;gt;name , x-&amp;gt;elemSize); noSpace = x-&amp;gt;totUsed == x-&amp;gt;totAlloc; if (noSpace || (q = GetElem(x-&amp;gt;heap , x-&amp;gt;elemSize , x-&amp;gt;type)) == NULL) { // 有空间的情况下，搜索存在至少一个空闲element的block，每次也只能分配一个element。 // BlockReorder遍历所有block 如果存在满足要求的block，移动到最前面。 if (!noSpace) BlockReorder(&amp;amp;(x-&amp;gt;heap), 1); // MHEAP没有空间，或者分配失败 if (noSpace || (q = GetElem(x-&amp;gt;heap, x-&amp;gt;elemSize, x-&amp;gt;type)) == NULL) { // curElem记录当前最大block分配element个数，num为根据增长因子growf自适应增长后的大小，但同时被 //maxElem约束 num = (size_t) ((double)x-&amp;gt;curElem * (x-&amp;gt;growf + 1.0) + 0.5); if (num &amp;gt; x-&amp;gt;maxElem) num = x-&amp;gt;maxElem; // 分配新block newp = AllocBlock(x-&amp;gt;elemSize, num, x-&amp;gt;type); // x-&amp;gt;totAlloc和 num都是element的个数; x-&amp;gt;totAlloc += num; x-&amp;gt;curElem = num; // 头插法放入表头，即新分配的block永远为第一个block newp-&amp;gt;next = x-&amp;gt;heap; x-&amp;gt;heap = newp; if ((q=GetElem(x-&amp;gt;heap, x-&amp;gt;elemSize, x-&amp;gt;type)) == NULL) HError(5191,&quot;New: null elem but just made block in heap %s&quot;, x-&amp;gt;name); } } // 虽然可能分配的block很大，但是分配给用户的elem个数 = 1 x-&amp;gt;totUsed++; if (trace&amp;amp;T_MHP) printf(&quot;HMem: %s[M] %u bytes at %p allocated\\n&quot;, x-&amp;gt;name, size, q); return q; case CHEAP: // 在每次申请内存时多分配一个sizeof(size_t)大小的空间：chdr，用于记录分配内存的大小。 chdr = MRound(sizeof(size_t)); q = malloc(size+chdr); //直接使用malloc分配 if (q==NULL) HError(5105,&quot;New: memory exhausted&quot;); x-&amp;gt;totUsed += size; x-&amp;gt;totAlloc += size+chdr; ip = (size_t *)q; *ip = size; if (trace&amp;amp;T_CHP) printf(&quot;HMem: %s[C] %u+%u bytes at %p allocated\\n&quot;, x-&amp;gt;name, chdr,size, q); return (Ptr)((ByteP)q+chdr); case MSTAK: // 用户可以申请任意大小的内存，但elementSize被限制为1bytes if (x-&amp;gt;protectStk) size += sizeof(Ptr); size = MRound(size); // 由于MSTACK的性质，导致每次只能从表头分配内存或者释放内存。不再有查找空余内存的动作(BlockReorder) if ((q = GetElem(x-&amp;gt;heap, size, x-&amp;gt;type)) == NULL) { // 每次分配bytes大小的新block bytes = (size_t)((double)x-&amp;gt;curElem * (x-&amp;gt;growf + 1.0) + 0.5); if (bytes &amp;gt; x-&amp;gt;maxElem) bytes = x-&amp;gt;maxElem; x-&amp;gt;curElem = bytes; // 由于bytes大小有突破x-&amp;gt;maxElem的可能性，所以可以重新分配 if (bytes &amp;lt; size) bytes = size; bytes = MRound(bytes); newp = AllocBlock(1, bytes, x-&amp;gt;type); x-&amp;gt;totAlloc += bytes; // 新block位置和MHEAP操作一致 newp-&amp;gt;next = x-&amp;gt;heap; x-&amp;gt;heap = newp; if ((q=GetElem(x-&amp;gt;heap, size, x-&amp;gt;type)) == NULL) HError(5191,&quot;New: null elem but just made block in heap %s&quot;,x-&amp;gt;name); } x-&amp;gt;totUsed += size; if (trace&amp;amp;T_STK) printf(&quot;HMem: %s[S] %u bytes at %p allocated\\n&quot;, x-&amp;gt;name, size, q); if (x-&amp;gt;protectStk) { pp = (Ptr *)((long)q + size - sizeof(Ptr)); *pp = q; } return q; } return NULL;}static void *GetElem(BlockP p, size_t elemSize, HeapType type){ int i,index; if (p == NULL) return NULL; switch (type) { case MHEAP: // MHEAP由于每次只能分配一个element，所以会维护一个table:p-&amp;gt;used，用于查找下一个空闲elem索引。 if (p-&amp;gt;numFree == 0) return NULL; index = p-&amp;gt;firstFree; //第一个空闲elem index，直接分配给用户 p-&amp;gt;used[p-&amp;gt;firstFree/8] |= 1&amp;lt;&amp;lt;(p-&amp;gt;firstFree&amp;amp;7); //table对应索引位置flag置1 p-&amp;gt;numFree--; // 查找下一个空闲元素索引，为下一次分配elem做准备。当没有空闲元素时p-&amp;gt;firstFree指向最后一个elem的下一个index。 if (p-&amp;gt;numFree &amp;gt; 0) { for (i=p-&amp;gt;firstFree+1; i&amp;lt;p-&amp;gt;numElem;i++) { if ((p-&amp;gt;used[i/8] &amp;amp; (1 &amp;lt;&amp;lt;(i&amp;amp;7))) == 0) { p-&amp;gt;firstFree = i; break; } } } else p-&amp;gt;firstFree = p-&amp;gt;numElem; return (void *)((ByteP)p-&amp;gt;data+index*elemSize); //返回分配的数据区指针 case MSTAK: // 栈顶的block不满足要求直接返回。比较简单，因为 if (p-&amp;gt;numFree &amp;lt; elemSize) return NULL; index = p-&amp;gt;firstFree; p-&amp;gt;firstFree += elemSize; p-&amp;gt;numFree = p-&amp;gt;numFree - elemSize; return (void *)((ByteP)p-&amp;gt;data + index); //返回分配的数据区指针 default: HError(5190,&quot;GetElem: bad type %d&quot;, type); } return NULL;}void Dispose(MemHeap *x, void *p) //从内存堆x中释放p{ BlockP head , cur , prev; Boolean found = FALSE; ByteP bp; size_t size,chdr; size_t num,index, *ip; Ptr *pp; if (x-&amp;gt;totUsed == 0) HError(5105 , &quot;Dispose: heap %s is empty&quot; , x-&amp;gt;name); switch(x-&amp;gt;type) { case MHEAP: // 支持链表中任意block的删除操作 head = x-&amp;gt;heap; cur=head; prev=NULL; size = x-&amp;gt;elemSize; while (cur != NULL &amp;amp;&amp;amp; !found) { num = cur-&amp;gt;numElem; // 判断指针在该位置 found = cur-&amp;gt;data &amp;lt;= p &amp;amp;&amp;amp;(((void*)((ByteP)cur-&amp;gt;data+(num-1)*size)) &amp;gt;= p); if (!found) { prev=cur; cur=cur-&amp;gt;next; } } if (cur == NULL) HError(5175,&quot;Dispose: Item to free in MHEAP %s not found&quot;,x-&amp;gt;name); index = ((size_t)p-(size_t)cur-&amp;gt;data)/size; cur-&amp;gt;used[index/8] &amp;amp;= ~(1 &amp;lt;&amp;lt;(index&amp;amp;7)); if (index &amp;lt; cur-&amp;gt;firstFree) cur-&amp;gt;firstFree = index; cur-&amp;gt;numFree++; x-&amp;gt;totUsed--; // 如果该block没有elem被使用，则释放 if (cur-&amp;gt;numFree == cur-&amp;gt;numElem) { if (cur != head) prev-&amp;gt;next = cur-&amp;gt;next; else head = cur-&amp;gt;next; x-&amp;gt;heap = head; x-&amp;gt;totAlloc -= cur-&amp;gt;numElem; free(cur-&amp;gt;data); free(cur-&amp;gt;used); free(cur); } if (trace&amp;amp;T_MHP) printf(&quot;HMem: %s[M] %u bytes at %p de-allocated\\n&quot;, x-&amp;gt;name, size, p); return; case MSTAK: // 由于MSTACK遵从LIFO，因此要想释放掉p所在的block，需要将之前的block全部释放才能释放处于栈顶的p所在的block cur = x-&amp;gt;heap; if (x-&amp;gt;protectStk) { if (cur-&amp;gt;firstFree &amp;gt; 0 ) pp = (Ptr *)((size_t)cur-&amp;gt;data+cur-&amp;gt;firstFree-sizeof(Ptr)); else { if (cur-&amp;gt;next == NULL) HError(5175,&quot;Dispose: empty stack&quot;); pp = (Ptr *)((size_t)cur-&amp;gt;next-&amp;gt;data+cur-&amp;gt;next-&amp;gt;firstFree-sizeof(Ptr)); } if (*pp != p) HError(-5175,&quot;Dispose: violation of stack discipline in %s [%p != %p]&quot;, x-&amp;gt;name, *pp, p); } while (cur != NULL &amp;amp;&amp;amp; !found) { num = cur-&amp;gt;numElem; found = cur-&amp;gt;data &amp;lt;= p &amp;amp;&amp;amp; (((void*)((ByteP)cur-&amp;gt;data+num)) &amp;gt; p); if (!found) { x-&amp;gt;heap = cur-&amp;gt;next; x-&amp;gt;totAlloc -= cur-&amp;gt;numElem; x-&amp;gt;totUsed -= cur-&amp;gt;firstFree;//fristFree体现了使用量 free(cur-&amp;gt;data); free(cur); cur = x-&amp;gt;heap; if (trace&amp;amp;T_STK) printf(&quot;HMem: deleleting block in %s[S]\\n&quot;, x-&amp;gt;name); } } if (!found) HError(5175,&quot;Dispose: Item to free in MSTAK %s not found&quot;, x-&amp;gt;name); // CAUTION:block内同样遵循stack准则，会将p之后不属于p指针指向的内存空间一块释放掉。 size = ((ByteP)cur-&amp;gt;data + cur-&amp;gt;firstFree) - (ByteP)p; //分配数据区的实际大小 if (size &amp;lt; 0) HError( 5175 , &quot;Dispose: item to free in MSTAK %s is above stack top&quot;, x-&amp;gt;name); cur-&amp;gt;firstFree -= size; cur-&amp;gt;numFree += size; x-&amp;gt;totUsed -= size; if (trace&amp;amp;T_STK) printf(&quot;HMem: %s[S] %u bytes at %p de-allocated\\n&quot;, x-&amp;gt;name, size, p); return; case CHEAP: // 只需要注意释放内存时释放储存分配空间大小的chdr空间即可。 chdr = MRound(sizeof(size_t)); bp = (ByteP)p-chdr; ip = (size_t *)bp; x-&amp;gt;totAlloc -= (*ip + chdr); x-&amp;gt;totUsed -= *ip; free(bp); if (trace&amp;amp;T_CHP) printf(&quot;HMem: %s[C] %u+%u bytes at %p de-allocated\\n&quot;, x-&amp;gt;name, chdr, *ip, bp); return; }}" }, { "title": "kaldi解码器基本原理、设计思想与代码简析", "url": "/posts/kaldi%E8%A7%A3%E7%A0%81%E5%99%A8%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86-%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3%E4%B8%8E%E4%BB%A3%E7%A0%81%E7%AE%80%E6%9E%90/", "categories": "ASR, KALDI", "tags": "writing", "date": "2021-11-08 21:10:00 +0800", "snippet": "　　本文以faster-decoder和lattice-decoder两个解码器为实例分别介绍kaldi解码器的基本原理、设计思想和代码简析。首先介绍两种解码器的基本功能与产物，然后介绍基于viterbi朴素实现的解码器的局限性，并给出kaldi中faster-decoder的优化方法和解决方案。最后以lattice-decoder为例给出代码实现简析。　　两种解码器原理基本一致，lattice-decoder相比faster-decoder在token-passing时建立了一个额外的前向链接，可以方便的记录state-level的拓扑结构，从而会产生额外的实现逻辑。因此后续章节以faster-decoder为例介绍解码器的基本原理，以lattice-decoder为例进行代码剖析。1 基本功能与产物　　Decoder基本功能是给定声学特征序列的声学模型得分，如何在基于WFST构建的HCLG网络中寻找one-best(最优路径)，即faster-decoder实现的最终产物。但很多时候需要保留更多的解码路径以便后续算法处理，这时候解码结果一般是一个lattice(网格) ，lattice是fst或者fsa及其变体，即lattice-faster-decoder实现的最终产物，后文统一简称lattice-decoder。1.1 input/outputfaster-decoder和lattice-decoder解码器输入输出形式基本一致，只是含义略有不同。   faster-decoder lattice-decoder input HGLC.fst和decodable实例引用 HGLC.fst和decodable实例引用 mid product state-level fst (linear fst) state-level fst (fst) output word-level one-best word-lattice(1.注意和N-best区别; 2.提供compact lattice形式) 1.2 one-best　　one-best可以直接是word序列，也可以是linear fst，其每个arc的output symbol都是一个word。　　one-best使用场景比较单一，只有超参数族给定，且模型、优化准则及数据分布都满足假设时，能够直接给出最优识别词序列，简单明了。1.3 lattice　　lattice没有非常确切的定义，不同应用场景下，其arc上的五元组(src_node,dst_node,input symbols,output symbols,weight)内容和形式可能略有不同。当lattice中arc上的output symbol为word时，一般称之为word-lattice(词格)。使用lattice的原因有很多，如以下几点： 当前解码图不能够反应数据的真实分布，从而产生偏差，需要更多信息的加入才能够获得更加准确的one-best，使用场景例如lm-rescoring。 当前解码准则是最小化句错误率(SER)，与常用ASR评价标准(WER)存在失配问题，则可以使用基于lattice的MBR解码。 鉴别性训练时，无法提供全部的解码路径信息，所以使用lattice解码结果近似全部解码空间（由于解码空间的稀疏性，该假设同样使用基于beam的解码路径裁剪）。 对语音数据进行解码时，可以在lattice上搜索acoutic model weight,language model weight,word insert penalty最优超参数组合，避免手动设计参数，以期达到整体asr模型的最优性能。 2 faster-decoder解码器基本原理和设计思想　　基于HCLG解码图的搜索最优路径问题等价于在有向无环图中求解两个节点之间的最短距离，求解方法有很多，其中viterbi算法最为常用，属于图的广度优先搜索算法(BFS)。viterbi算法在序列解码中很高效，不存在重复计算的问题。算法原理不再赘述，这里只介绍其朴素实现思想的局限性及优化方法(kaldi faster-decoder实现方式)。2.1 viterbi算法　　维特比算法(Viterbi Algorithm)是一种动态规划算法。维特比算法由安德鲁·维特比(Andrew Viterbi)于1967年提出，用于在数字通信链路中解卷积以消除噪音。此算法被广泛应用于CDMA和GSM数字蜂窝网络、拨号调制解调器、卫星、深空通信和802.11无线网络中解卷积码。现今也被常常用于语音识别、关键字识别、计算语言学和生物信息学中。原理和具体实现这里不再赘述，只给出朴素使用viterbi算法朴素实现语音识别的基本流程： 维护一个dp table用来记录已经计算过的路径信息，路径信息包含当前帧路径节点路径累计cost和上一帧最优路径节点Index，其中累计cost：accumulate_cost += cur_acoutice_cost + cur_graph_cost。 利用动态规划不断求解每一帧所有节点的路径信息，并填写dp table，当所有帧处理完毕后，获得最优路径节点的Index，并根据dp table中记录的上一帧最优路径节点的Index进行路径回溯。 对应发音词典index转换为word序列。 2.2 viterbi朴素实现的问题1.dp table占用内存过大　　viterbi算法属于动态规划问题，动态规划问题需要维护一个dp table用来记录已经计算过的路径信息。dp table大小为num_frames*num_nodes*cell，其中每一个cell都是一个路径node信息，至少包括两个方面的信息：cur_total_cost和backtrace_pointer。两个信息分别用于前向计算路径累计代价和反向回溯最优路径。以cell只包含前述两个信息为例：100 (frames/sec)*10M (nodes)*8Bytes ≈ 8GB/sec 。这个内存占用规模在许多系统尤其是嵌入式上基本不可容忍。2.时间复杂度无法满足实际使用　　依然采用上述参数，计算复杂度为：100 (frames/sec)*10M (nodes)*100 (cycles/state) ≈ 10^11cycles/sec　　这个水平在CPU 1G主频的嵌入式硬件平台上不可实现，如1G主频的CPU。即使在一些高性能计算平台上能够达到RTF&amp;lt;=1的水平，也要考虑其综合效益问题。2.3 优化思路1.只保留相邻两帧的信息，优化dp table　　由于hmm state上的信息量满足一阶马尔可夫假设，所以当前state只依赖于上一个时刻的state，因此在实现dp table的时候可以，只保留相邻两帧的信息即可。2.基于解码图稀疏性假设，采用token-passing和prune算法　　解码图路径满足稀疏性假设，只有不到1%的解码路径会对最终的one-best路径产生影响，因此没有必要在任意时刻计算和存储所有的node的路径信息。由于固定大小的dp table无法满足这种需求，因此采用了更加灵活的token-passing算法。token-passing算法灵活性体现在任意时刻能够保留任意数量的token，从而利于各种prune算法的实现。但是灵活的token面临着遍历查找的问题，所以kaldi采用了更加灵活的hashlist存储任意时刻的所有tokens，hashlist的解析会在其他博文中展开，其优点是近似O(1)的查找时间。2.4 prune算法及实现　　基本思想：设置累计代价最大门限threshold_accumulate_cost，对当前帧emitting arcs不满足threshold_accumulate_cost1的token进行垃圾回收，对下一帧emitting arcs或其后续nonemitting arc不满足门限的threshold_accumulate_cost2不进行token passing。kaldi采用了手动设计两种剪枝方式混合搭配的方式自适应更新prune算法参数threshold_accumulate_cost，一种是beam-search(注意这里的beam和其他算法语境下的beam参数-存活路径个数略有区别)，另一种是active-tokens restriction。kaldi实现方式如下： 手动设置beam-width,active-tokens(max-active/min-active)两个相关参数 算法自适应根据初始beam-width和active-tokens更新beam-width,kaldi中还涉及一个自适应更新时用到的beam-delta，防止自适应更新的beam-width过于紧凑，导致剪枝掉可能的解码路径。 利用max_cost剪枝当前帧的tokens获得active-tokens，同时获得apative_beam，对应流程图中① 利用adaptive_beam计算得到next_weight_cutoff剪枝从当前nodes传递到emitting arcs的tokens，更新next_weight_cutoff，对应流程图中②。 利用next_weight_cutoff剪枝下一帧从emitting arcs传递到后续nonemitting arcs上的tokens，对应流程图中③。 ​ prune流程图如下：2.4 路径回溯　　路径回溯发生在两种情况decoder.ReachedFinal() == True或者allow_partial == True。满足这两种情况会进行路径回溯。流程如下： 路径回溯获得的逆序线性arcs。 删除解码器初始化时带来的virtual token。 正序获得one-best路径中所有的arcs。 删除部分epsilons，获得等价线性fst，解码器核心实现就到此位置。 如果想要获得词级别结果，使用GetLinearSymbolSequence获得word-level解码结果。 3 lattice-decoder解码器代码实现　　本文从lattice-decoder介绍kaldi的代码实现，并略带展示和faster-decoder的实现差异，两者原理基本一致，不同之处在于为了方便了记录lattice路径，而在token-passing时，创建了ForwardLink，因此导致了一些额外的实现。　　lattice实现了LatticeFasterDecoderTpl类模板，所有lattice-decoder的相关实现都是通过继承或者直接实例化该类模板。解码时为了高效，内部将FST转化为更加明确的类型。3.1 重要接口与数据结构​ interface purpose data structrue purpose Decode() 解码器最上层接口 ForwardLink 记录有效路径两个token之间的前向连接 InitDecoding() 初始化 StdToken lattice解码使用的标准token AdvanceDecoding() 解码 BackpointerToken 相对于StdToken额外记录了回溯信息，利于快速获取最优路径。 FinalizeDecoding() 终止并清理现场 TokenList 记录每帧的active tokens GetBestPath() 获取最优路径     GetRawLattice() 获得state-level fst             3.2 代码简析解码的核心代码实现在AdvanceDecoding()中: while (NumFramesDecoded() &amp;lt; target_frames_decoded) { if (NumFramesDecoded() % config_.prune_interval == 0) { // 每隔config_.prune_interval会对lattice进行prune，防止lattice路径过于庞大。 PruneActiveTokens(config_.lattice_beam * config_.prune_scale); } // 处理emitting arc BaseFloat cost_cutoff = ProcessEmitting(decodable); // 处理nonemitting arc ProcessNonemitting(cost_cutoff); }​lattice的生成核心代码在getrawlattice()中：for (int32 f = 0; f &amp;lt;= num_frames; f++) { for (token *tok = active_toks_[f].toks; tok != null; tok = tok-&amp;gt;next) { // 利用forwardlink构建lattice stateid cur_state = tok_map[tok]; for (forwardlinkt *l = tok-&amp;gt;links; l != null; l = l-&amp;gt;next) { arc arc(l-&amp;gt;ilabel, l-&amp;gt;olabel, weight(l-&amp;gt;graph_cost, l-&amp;gt;acoustic_cost - cost_offset), nextstate); // 建立空fst，并按照拓扑结构建立state和its outgoing arcs ofst-&amp;gt;addarc(cur_state, arc); } } } }3.3 核心实现流程1.ProcessEmitting()　　该函数是实现了token-passing时emitting arc的处理。流程： 遍历每一个当前active token，对于outgoing emitting arc进行处理，使用前述prune算法对当前帧active token剪枝 进行token passing，对下一帧的token进行剪枝。 对于满足约束条件的下一帧的token，利用FindOrAddToken()查找替换cost较大的现有tokens或者直接插入新的token。 构建从父token到当前token的forwardlinkT。2.ProcessNonemitting()　　该函数是实现了Token-passing时的nonemitting arc的处理，其使用了DFS(深度优先遍历)，迭代遍历nonemitting arc的所有successors。流程： 获取全部emitting tokens。 设置一个stack，用于DFS。 清空当前token的forward link，重新生成更优的forward link。 前向遍历不断进行token passing 并建立forward link。" } ]
