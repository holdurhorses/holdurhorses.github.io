---
title: 语音合成不同时期的技术特点和核心原理
author: Zhang
date: 2021-12-4 21:10:00 +0800
categories: [TTS, review]
tags: [writing]
render_with_liquid: false　
---

　　TTS(Text-to-Speech)本质上是解决输入文本到输入语音的不定长映射问题。和ASR具有很大的相似性，但是又具有one-to-many技术特点而带来诸多难点。各位前辈的技术博客和各类论文都会对TTS技术原理和特点都有专业、详尽的描述，但是想起刚入门时面对众多技术路线，又不知从何下手的困境，觉得还是有必要沉淀一篇带有**核心原理**的方向性综合论述博文。本文给出不同时期TTS技术的基本特点，同时对核心技术原理进行阐释。

# 技术分类

TTS技术大类上基本划分一致，但是在技术子类上尤其涉及End-to-end speech synthesis上，可能有多种划分方法，如：

- 根据端对端任务覆盖程度：部分功能模块变成端对端任务和全部功能模块变成了端对端任务
- 根据模型特点：自回归和非自回归模型

本文采用自回归和非自回归模型两类介绍曾经的热门模型tacotron1/2和fastspeech1/2/2s。同时在Concatenative speech synthsis之前也有很多技术路线，但是由于略微久远，这里先不在记录了，先关注优先级更高一些的技术路线吧。

| 技术大类                                | 技术子类                                                     |
| --------------------------------------- | ------------------------------------------------------------ |
| Concatenative speech synthsis           | diphone synthesis<br />unit selection synthesis              |
| Statistical parametric speech synthesis | hmm-based parametric speech synthesis<br />dnn-based parametric speech synthesis |
| End-to-end speech synthesis             | auto-regression model <br />non-autoregression model         |

# Concatenative speech synthsis

　　拼接法基本思想就是录制特定说话人的语音库，将每句话的按照特定的建模单元进行分割，组成语音候选单元库，在合成阶段根据输入文本从语音候选单元库中，选择合适的基本单元进行拼接重组获得最终合成的语句。每种建模单元对应的候选单元可以有一个或者多个时。diphone是英文常见的建模单元，其候选单元只有一个，也可能获得较好的合成效果，即diphone synthesis。而当候选单元有多个时，需要根据文本上下文选择不同的候选单元，即unit selection synthesis。

优缺点可参考paper[3]

- 优点： high intelligibility and authentic timbre close to the original voice actor
- 缺点： less natural and emotional，result in less smoothness in stress, emotion, prosody，large database

## diphone synthesis

　　diphone synthesis，一般指每个基本合成单元的**候选单元只有一个**，基于双音子的语音合成模型认为协同发音现象主要出现在音素边界上,即相邻单音素的拼接点上,而在音 素中部稳定段的发音比较稳定,所以双音子选择协同发音较为弱的音素稳定段作为拼接点，即diphone可以大幅度减轻在Phone和phone边界处的协同发音问题，在早期英文语音合成 中广泛应应用。diphone synthesis也有unit selection 版本的算法，即每个diphone有多个候选单元。但是最早期的diphone可以使用非常少的diphone set（like: 44 basic units）合成相对流畅的语音。

核心步骤：

1.  录音准备预料

2.  分段和对齐（早期对齐直接采用DTW，用来和benchmark语料库进行对齐）

3.  音频片段音质检查和边界检查

4.  基频提取（非常重要，拼接法中的核心算法之一就是PSOLA及其变种: TD-PSOLA,FD-PSOLA,LP-PSOLA...）

5.  根据lexicon将文本转化为phone sequence。

   （如果是unit selection可以包含更多模块，如：text analysis, lexicons and prosodic models）

6.  最终从库中选择对应片段使用PSOLA算法进行拼接和处理

## unit selection synthesis　

　　unit selection synthesis，一般指每个基本合成单元的**候选单元有多个（ candidates）**，有多个意味着prosody可控可选，可以合成更加丰富的语句，但是同时意味着需要额外的信息和算法选择合适的 candidate。额外的信息一般指如何从文本获得目标音频信息，算法指根据该音频信息获得对应的最匹配的候选单元序列。

　　首先需要通过文本获取target需要满足的条件，有了target的确切要求(音素、上下文、韵律等等)可以通过算法选择合适的 candidate unit，而合适的 candidate要满足两种条件，一种是 candidate要和target 在多种 feature上匹配，另一种要该 candidate要和上下文的 candidate衔接紧密，即声学特征连续性好。在这两个条件的约束下，通过合适的算法就可以选择合理的候选音频片段。

###  **a. feature vector**

衡量target和 candidate的feature vector一般包括以下几个方面：

- 连续变量：pitch,duration,power
- 离散变量：前驱phoneme，后继phoneme，是vowel 还是consonant等等。

衡量 candidate和context  candidate的feature vector一般包括以下几个方面：

- 连续变量：pitch,cepstral distance,power

Q1:feature 距离衡量方式?

　　连续变量直接可以算距离，而离散变量遵循简单的原则，target和unit是一致则为1否则为0。

Q2:feature如何提取?

　　对文本进行文本分析，获取linguistic feature，通过regression tree可以获得连续变量。

离散变量直接通过question set对linguistic feature离散化。

### **b. constraint**

两个约束表述如下：
$$
\begin{equation}
C^{t}\left( t_{i},u_{i}\right) =\sum ^{p}_{j=1}w_{j}^{t}C_{j}^{t}\left( ti,u_{i}\right) 
\end{equation}
$$

$$
\begin{equation}
C^{c}\left( u_{i-1},u_{i}\right) =\sum ^{q}_{j=1}w_{j}^{c}C_{j}^{c}\left( u_{i-1},u_{i}\right)\label{1}
\end{equation}
$$

公式(1)为target cost，由多个subcost组成，每个subcost对应一个feature，不同的实现p的取值不同，如p=40。

公式(2)为concatenative cost，由多个subcost组成，每个subcost对应一个feature，常见的就是q=3，共三个特征（pitch,cepstral distance,power）。

Q1:weights如何选择?

　　weights的选择非常关键，选择合适的weights对最终合成的语音音质很重要。有两种方案一种是 weight space search 在有限的参数空间中进行搜索.，另一种regression training可以穷尽参数搜索。

### **c.  algorithm**

viterbi算法+prune算法，这里不再赘述算法原理。

 Q1: 大型database可能超过100,000 units，如何进行有效搜索？

　　数据库搜索和HMM解码问题非常像，当前candidate只依赖当前target，最优hidden sequences对应的就是最优的candidate sequences，转移概率和发射概率分别使用了concatenate cost和target cost代替，所以最优路径的搜索可以选择viterbi算法，同时使用beam search（如：beam=20units）方法可以更快速的解码。



# Statistical parametric speech synthesis

　　统计参数合成法的整体路线已经和最近几年层出不穷各种技术路线基本一致，理解统计参数合成法对于端对端网络真正工程化落地也非常重要。核心三个模块：

- text analysis :文本分析用于text转化成语言学特征linguistic feature（随着技术发展，该模块功能的输入输出会有所变化），包含了text normalization , grapheme-to-phoneme conversion, word segmentation，prosody prediction，quesitons set等等。
- acoustic model and duration model：用于linguistic feature映射成acoustic feature.
- vocoder ：用于acoustic feature产生语音。

从上述关键的三个模块可以看出，其中关键的两个特征是linguistic feature和acoustic feature：

- linguistic feature：音素在音节的位置信息，前驱音素后置音素，重音、音调标注等等，多达几十种的基于语言学的上下文描述信息。
- acoustic feature：取决于vocoder的建模方式。在SPSS技术时期主要的声码器有两种straight和world。两者都是基于source-filter模型，原理基本一致。需要的输入有三种：MGC(mel-generalized coefficients，用于vocal tract的建模)，F0(pitch，用于voiced语音声带激励源建模)，BAP(band aperiodicities，与F0一起用于声带混合激励源的建模，能够让激励更加真实)。

　　这两个特征的映射关系可以从hmm-based model给出也可以从dnn-base model给出。但是注意dnn-based model还省去了hmm-based SPSS中的regression tree-based context tying。下文展开linguistic feature和acoustic feature建模原理，但对text normalization和vocoder 粗略描述，在dnn-based SPSS语境下的详细原理可以参照后续关于Merlin[4]（基于dnn-based SPSS的开源python实现）的博文。当我们将文本输入text normalization后，会获得多个离散的linguistic feature。但是要想获得frame-level aoucstic feature还要给出duration prediction和phoneme-level acoutic feature，两种经典方法的解决方案如下。

## hmm-based SPSS

　　更确切地hmm-based SPSS应该称之为regression tree-based SPSS，这是因为决定linguistic feature和acoustic feature映射关系的模型不是hmm而是tree。

## dnn-based SPSS

# reference

[1] Concatenative Speech Synthesis: A Review

[2] PITCH-SYNCHRONOUS WAVEFORM PROCESSING TECHNIQUES FOR  TEXT-TO-SPEECH SYNTHESIS USING DIPHONES 

[3] A Survey on Neural Speech Synthesis

[4] Merlin: An Open Source Neural Network Speech Synthesis System
